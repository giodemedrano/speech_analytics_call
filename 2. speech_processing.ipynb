{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import statistics\n",
    "import os\n",
    "import logging\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.util import ngrams, bigrams\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px #Graficos interactivos\n",
    "\n",
    "mypath = 'Voicebot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = logging.handlers.WatchedFileHandler(os.environ.get(\"LOGFILE\", f\"{mypath}/debug.log\"))\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root = logging.getLogger()\n",
    "root.setLevel(os.environ.get(\"LOGLEVEL\", \"INFO\"))\n",
    "root.addHandler(handler)\n",
    "logging.info(f\"INICIO PROCESO '2.speech_processing.ipynb'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(f'{mypath}/transcripts/json/') if isfile(join(f'{mypath}/transcripts/json/', f))]\n",
    "logging.info(f\"{len(onlyfiles)} files inside '{mypath}/transcripts/json'\")\n",
    "jsonfiles = [os.path.splitext(filename)[0] for filename in onlyfiles if os.path.splitext(filename)[1]=='.json']\n",
    "logging.info(f\"{len(onlyfiles)} jsonfiles inside '{mypath}/transcripts/json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load .json\n",
    "rawdata = []\n",
    "rawinfo = []\n",
    "\n",
    "for jsonfile in jsonfiles:\n",
    "  with open(f\"{mypath}/transcripts/json/{jsonfile}.json\", encoding='utf8') as json_file:\n",
    "    rawdata.append(json.load(json_file)) # Transcripts and data\n",
    "\n",
    "with open(f\"{mypath}/transcripts/info/times.json\", encoding='utf8') as json_file:\n",
    "  for times in json.load(json_file):\n",
    "    rawinfo.append(times) # Time of processing transcriptions\n",
    "  \n",
    "# data = rawdata[0]\n",
    "logging.info(f\"{len(rawdata)} files append to rawdata\")\n",
    "print(f\"{len(rawdata)} files appended to rawdata\")\n",
    "logging.info(f\"{len(rawdata)} times extracted from '{mypath}/transcripts/info/times.json'\")\n",
    "print(f\"{len(rawdata)} times extracted from '{mypath}/transcripts/info/times.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.keys()                       # dict_keys(['audio_metrics', 'results', 'result_index', 'speaker_labels'])\n",
    "## data['audio_metrics'].keys()     # dict_keys(['sampling_interval', 'accumulated'])\n",
    "## data['results'][0].keys()        # dict_keys(['alternatives', 'final'])\n",
    "## data['result_index']             # 0\n",
    "## data['speaker_labels'][0].keys() # dict_keys(['from', 'to', 'speaker', 'confidence', 'final'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info data: audio metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  data['audio_metrics'].keys()                                    # dict_keys(['sampling_interval', 'accumulated'])\n",
    "###                      # 0.1 [seconds] *\n",
    "### data['audio_metrics']['accumulated'].keys()                     # dict_keys(['non_speech_level', 'clipping_rate', 'high_frequency_loss', 'end_time', 'speech_ratio',                                                                                      'direct_current_offset','final', 'signal_to_noise_ratio', 'speech_level'])\n",
    "### data['audio_metrics']['accumulated']['non_speech_level']        # Non-Speech levels *                \n",
    "### data['audio_metrics']['accumulated']['clipping_rate']           # Clipping rates\n",
    "### data['audio_metrics']['accumulated']['high_frequency_loss']     # 0.0\n",
    "### data['audio_metrics']['accumulated']['end_time']                # 147.6 [seconds] *\n",
    "### data['audio_metrics']['accumulated']['speech_ratio']            # 0.732 [speech_time/end_time] *\n",
    "### data['audio_metrics']['accumulated']['direct_current_offset']   # Offset levels\n",
    "### data['audio_metrics']['accumulated']['final']                   # True\n",
    "### data['audio_metrics']['accumulated']['signal_to_noise_ratio']   # 12.8 *\n",
    "### data['audio_metrics']['accumulated']['speech_level']            # Speech levels *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Bads Requests...\n",
    "bads = []\n",
    "for i,data in enumerate(rawdata):\n",
    "    try: \n",
    "        data['error']\n",
    "        bads.append(i)\n",
    "    except:\n",
    "        pass\n",
    "if bads == []:\n",
    "    logging.info(f\"No bad requests transcripts found\")\n",
    "else: logging.warning(f\"Bad requests found: {bads}\")\n",
    "bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_metrics = []\n",
    "for i, data in enumerate(rawdata):\n",
    "    sampling_interval       = data['audio_metrics']['sampling_interval']\n",
    "    non_speech_level_freq   = [non_speech_level['count'] for non_speech_level in data['audio_metrics']['accumulated']['non_speech_level']]\n",
    "    non_speech_level_mean   = sum(freq*(i + 0.5)/10 for i, freq in enumerate(non_speech_level_freq))/sum(non_speech_level_freq) if sum(non_speech_level_freq) != 0 else 0\n",
    "    non_speech_level_var    = sum(freq*((i + 0.5)/10 - non_speech_level_mean)**2 for i, freq in enumerate(non_speech_level_freq))/sum(non_speech_level_freq) if sum(non_speech_level_freq) != 0 else 0\n",
    "    end_time                = data['audio_metrics']['accumulated']['end_time']\n",
    "    speech_ratio            = data['audio_metrics']['accumulated']['speech_ratio']\n",
    "    final                   = data['audio_metrics']['accumulated']['final']\n",
    "    # signal_to_noise_ratio   = data['audio_metrics']['accumulated']['signal_to_noise_ratio']\n",
    "    speech_level_freq       = [speech_level['count'] for speech_level in data['audio_metrics']['accumulated']['speech_level']]\n",
    "    speech_level_mean       = sum(freq*(i + 0.5)/10 for i, freq in enumerate(speech_level_freq))/sum(speech_level_freq) if sum(speech_level_freq) != 0 else 0\n",
    "    speech_level_var        = sum(freq*((i + 0.5)/10 - speech_level_mean)**2 for i, freq in enumerate(speech_level_freq))/sum(speech_level_freq) if sum(speech_level_freq) != 0 else 0\n",
    "    audio_metrics.append({  'file_id'               : i + 1,\n",
    "                            'path'                  : r\"\\\\192.9.100.44\\grabaciones\\CAT\\20210427\",\n",
    "                            'file_name'             : f\"{jsonfiles[i]}.ogg\",\n",
    "                            # 'time_transcription'    : rawinfo[i],                      \n",
    "                            'sampling_interval'     : sampling_interval,\n",
    "                            'has_ending'            : final,\n",
    "                            'speech_level_mean'     : speech_level_mean,\n",
    "                            'speech_level_var'      : speech_level_var,\n",
    "                            'non_speech_level_mean' : non_speech_level_mean,\n",
    "                            'non_speech_level_var'  : non_speech_level_var,\n",
    "                            # 'signal_to_noise_ratio' : signal_to_noise_ratio,\n",
    "                            'speech_ratio'          : speech_ratio,\n",
    "                            'time_call'             : end_time,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info data: results & speaker labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  data['results'][0]                                          # List of 'transcripts' divided according to pauses *\n",
    "##  data['results'][0].keys()                                   # dict_keys(['alternatives', 'final'])\n",
    "### data['results'][0]['alternatives'][0]                       # List of 'alternatives' to a specific 'transcript' *\n",
    "### data['results'][0]['alternatives'][0].keys()                # dict_keys(['timestamps', 'confidence', 'transcript', 'word_confidence']) \n",
    "### data['results'][0]['alternatives'][0]['timestamps'][0]      # List of 'timestamps' for each 'word' in 'transcript' with 'begin' and 'end'\n",
    "### data['results'][0]['alternatives'][0]['confidence']         # Value of 'transcript' 'confidence'\n",
    "### data['results'][0]['alternatives'][0]['transcript']         # Value of 'transcript'\n",
    "### data['results'][0]['alternatives'][0]['word_confidence'][0] # List of 'word_confidence' for each 'word' in 'transcript' with confidence value\n",
    "### data['speaker_labels'][0]                                   # List of 'speaker_labels' divided for timestamps\n",
    "### data['speaker_labels'][0].keys()                            # dict_keys(['from', 'to', 'speaker', 'confidence', 'final'])\n",
    "### data['speaker_labels'][0]['from']                           # Value of 'from' timestamp\n",
    "### data['speaker_labels'][0]['to']                             # Value of 'to' timestamp\n",
    "### data['speaker_labels'][0]['speaker']                        # Value of 'speaker' number\n",
    "### data['speaker_labels'][0]['confidence']                     # Value of 'confidence' number\n",
    "### data['speaker_labels'][0]['final']                          # True/False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporea y Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmkeys = ['word','begin','end','word_confidence','speaker','speaker_confidence','file_id'] # corpus_multi_keys\n",
    "corporea = []               # List of corpus (list of 'sentences' containing separated 'words' in a phone conversation)\n",
    "corporea_multi = []         # List of corpus_multi (list of 'sentences' containing separated 'words', 'timestamps', 'confidence', and 'speaker' in a phone conversation)\n",
    "corporea_multi_dict = []    # List of corpus_multi dictionaries (with labels)\n",
    "for n, data in enumerate(rawdata):\n",
    "    corpus = [[word[0] for word in alternative['timestamps']] for result in data['results'] for alternative in result['alternatives'][:1]]\n",
    "    corpus_flat = [group for sentence in corpus for group in sentence]\n",
    "    corpus_timestamps = [[group_times for group_times in alternative['timestamps']] for result in data['results'] for alternative in result['alternatives'][:1]]\n",
    "    corpus_confidence = [[group_confidence for group_confidence in alternative['word_confidence']] for result in data['results'] for alternative in result        ['alternatives'][:1]]\n",
    "    corpus_speaker = [data['speaker_labels'][sum(len(corpus[i]) for i in range(j)):sum(len(corpus[i]) for i in range(j+1))] for j, sentence in enumerate(corpus)]\n",
    "    corpus_extra = [[(group + [corpus_confidence[i][j][-1]]) for j, group in enumerate(corpus_timestamps[i])] for i, sentence in enumerate(corpus_timestamps)]\n",
    "    corpus_multi = [[(group + [corpus_speaker[i][j]['speaker']] + [corpus_speaker[i][j]['confidence']] + [n+1]) for j, group in enumerate(corpus_extra[i])] for i, sentence in enumerate(corpus_extra)]\n",
    "    corpus_multi_flat = [group for sentence in corpus_multi for group in sentence]\n",
    "    corpus_multi_dict = [[dict(zip(cmkeys, word_group)) for word_group in sentence] for sentence in corpus_multi]\n",
    "    corpus_multi_dict_flat = [group for sentence in corpus_multi_dict for group in sentence]\n",
    "    corporea.append(corpus_flat)\n",
    "    corporea_multi.append(corpus_multi_flat)\n",
    "    corporea_multi_dict.append(corpus_multi_dict_flat)\n",
    "# corporea_multi_dict[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_speakers = []\n",
    "for corpus_multi_dict in corporea_multi_dict:\n",
    "    for word in corpus_multi_dict:\n",
    "        if word['speaker'] not in total_speakers: total_speakers.append(word['speaker'])\n",
    "speaker_label = [\"Speaker_f\", \"Speaker_s\"]\n",
    "for i in range(len(total_speakers)): \n",
    "    speaker_label.append(f'Speaker_{i}')\n",
    "speaker_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df = pd.DataFrame(columns=speaker_label)\n",
    "\n",
    "for i,corpus_multi_dict in enumerate(corporea_multi_dict):\n",
    "    try:\n",
    "        words_counter = [0]*len(total_speakers)\n",
    "        first = corpus_multi_dict[0]['speaker']\n",
    "        second = first\n",
    "        for word in corpus_multi_dict:\n",
    "            if first == second:\n",
    "                if first != word['speaker']: \n",
    "                    second = word['speaker']\n",
    "            for id in range(len(words_counter)):\n",
    "                if word['speaker']==id: \n",
    "                    words_counter[id] += 1\n",
    "                    break\n",
    "                    \n",
    "        aux = {speaker_label[0]: first, speaker_label[1]: second}\n",
    "        for j in range(len(total_speakers)): \n",
    "            aux[speaker_label[j+2]] = words_counter[j]\n",
    "        \n",
    "        df = df.append(aux, ignore_index=True)\n",
    "    except:\n",
    "        df = df.append(pd.Series(), ignore_index=True)\n",
    "        pass\n",
    "        \n",
    "df.index += 1\n",
    "dft = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfiles[0].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO Extractions from filename\n",
    "# agent_result = [filename.split('_')[-1] for filename in jsonfiles] # The result is extracted from the filename if the file has it\n",
    "agent_name = [filename.split('_')[4] for filename in jsonfiles] # The result is extracted from the filename\n",
    "audio_cartera = [filename.split('_')[0] for filename in jsonfiles]\n",
    "audio_fecha = [filename.split('_')[2] for filename in jsonfiles]\n",
    "audio_hora = [filename.split('_')[3] for filename in jsonfiles]\n",
    "rut = [filename.split('_')[1] for filename in jsonfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select \"speaker\" who is \"agent\" and \"speaker\" who is \"client\"\n",
    "# agent_speaker = [corpus_multi_dict[0]['speaker'] for corpus_multi_dict in corporea_multi_dict] # The first in talk is considered the 'agent_speaker'\n",
    "agent_speaker = [list(dft[column])[2:].index(sorted(list(dft[column])[2:])[-1]) for column in dft.columns] # The 1st one that talk most is the 'agent_speaker'\n",
    "client_speaker = [list(dft[column])[2:].index(sorted(list(dft[column])[2:])[-2]) for column in dft.columns] # The 2nd one that talk most is the 'client_speaker'\n",
    "print(f'agent_speaker: {agent_speaker}')\n",
    "print(f'client_speaker: {client_speaker}')\n",
    "\n",
    "# agent_speaker: [0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
    "# client_speaker: [2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1, 2, 0, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 3, 0, 0, 0, 2, 1, 1, 3, 0, 0, 1, 1, 2, 2, 2, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 2, 0, 0, 2, 1, 1, 0, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 2, 1, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['Speaker_f'])):\n",
    "    if agent_speaker[i] != client_speaker[i]:\n",
    "        df['Speaker_f'][i+1] = agent_speaker[i]\n",
    "        df['Speaker_s'][i+1] = client_speaker[i]\n",
    "df = df.rename(columns={'Speaker_f':'agent_speaker', 'Speaker_s':'client_speaker'})\n",
    "dft = df.T\n",
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Swap manually the speakers\n",
    "# agent_swap = []\n",
    "# agent_swap = [5,12,14,21,22,24,26,29,32,34,35,41] # agents need to be corrected manually\n",
    "# agent_speaker = list(df['agent_speaker'])\n",
    "# client_speaker = list(df['client_speaker'])\n",
    "# for id in agent_swap:\n",
    "#     aux = agent_speaker[id-1]\n",
    "#     agent_speaker[id-1] = client_speaker[id-1]\n",
    "#     client_speaker[id-1] = aux\n",
    "# df['agent_speaker'] = agent_speaker\n",
    "# df['client_speaker'] = client_speaker\n",
    "# dft = df.T\n",
    "# dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MANUAL EXTRACT DATA\n",
    "# agent_type = ['outbound', 'outbound', 'outbound', 'outbound', 'outbound', 'outbound', 'inbound', 'outbound', 'outbound', 'outbound', 'outbound', 'outbound']\n",
    "# # agent_speaker = [0 for i in range(len(agent_result))]\n",
    "# agent_speaker = [0,0,0,0,0,0,0,1,0,1,0,0]\n",
    "# # agent_result = ['compromiso', 'no_contacto', 'no_contacto', 'compromiso', 'no_contacto', 'reclamo_facturación', 'compromiso', 'reclamo_baja', 'reclamo_baja', 'reclamo_facturación', 'no_contacto', 'compromiso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary of speaker n in multi_dic[i]\n",
    "# n = 1\n",
    "# i = 12\n",
    "# [{word[\"word\"],word[\"word_confidence\"]} for word in corporea_multi_dict[i-1] if word['speaker']==n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medida de riqueza lexica en un texto: \n",
    "$$ R_l = \\frac{\\text{total de palabras únicas}}{\\text{total de palabras}} = \\frac{\\text{longitud del vocabulario}}{\\text{longitud del texto}}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, corpus_multi_dict in enumerate(corporea_multi_dict):\n",
    "    audio_metrics[i]['time_voices']             = sum((word['end']-word['begin']) for word in corpus_multi_dict)\n",
    "    audio_metrics[i]['time_speaker_0']          = sum((word['end']-word['begin']) for word in corpus_multi_dict if word['speaker']==agent_speaker[i])\n",
    "    audio_metrics[i]['time_speaker_1']          = sum((word['end']-word['begin']) for word in corpus_multi_dict if word['speaker']==client_speaker[i])\n",
    "    audio_metrics[i]['voices_call_ratio']       = audio_metrics[i]['time_voices']/audio_metrics[i]['time_call'] if audio_metrics[i]['time_call'] != 0 else 0\n",
    "    audio_metrics[i]['agent_call_ratio']        = audio_metrics[i]['time_speaker_0'] /audio_metrics[i]['time_call'] if audio_metrics[i]['time_call'] != 0 else 0\n",
    "    audio_metrics[i]['agent_dominance']         = audio_metrics[i]['time_speaker_0'] /audio_metrics[i]['time_voices'] if audio_metrics[i]['time_voices'] != 0 else 0\n",
    "    audio_metrics[i]['agent_words_sum']         = sum( 1 for word in corpus_multi_dict if word['speaker']==agent_speaker[i])\n",
    "    audio_metrics[i]['client_words_sum']        = sum( 1 for word in corpus_multi_dict if word['speaker']==client_speaker[i])\n",
    "    audio_metrics[i]['agent_words_per_second']  = audio_metrics[i]['agent_words_sum']/audio_metrics[i]['time_speaker_0'] if audio_metrics[i]['time_speaker_0'] != 0 else 0\n",
    "    audio_metrics[i]['client_words_per_second'] = audio_metrics[i]['client_words_sum']/audio_metrics[i]['time_speaker_1'] if audio_metrics[i]['time_speaker_1'] != 0 else 0\n",
    "    audio_metrics[i]['agent_speaker']           = agent_speaker[i]\n",
    "    audio_metrics[i]['client_speaker']          = client_speaker[i]\n",
    "    audio_metrics[i]['agent_name']              = agent_name[i]\n",
    "    audio_metrics[i]['cartera']                 = audio_cartera[i]\n",
    "    audio_metrics[i]['audio_fecha']             = audio_fecha[i]\n",
    "    audio_metrics[i]['audio_hora']              = audio_hora[i]\n",
    "    audio_metrics[i]['rut']                     = rut[i]\n",
    "    audio_metrics[i]['nombre']                  = nombres[i]\n",
    "    audio_metrics[i]['calidad']                 = calidad[i]\n",
    "    # audio_metrics[i]['lexical_wealth ']         = len(set([word['word'] for word in corpus_multi_dict if word['speaker']==agent_speaker[i]]))/len([word['word'] for word in corpus_multi_dict if word['speaker']==agent_speaker[i]]) if len([word['word'] for word in corpus_multi_dict if word['speaker']==agent_speaker[i]]) != 0 else 0\n",
    "    audio_metrics[i]['conversation']            = documents[i]\n",
    "# audio_metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct dialogs new\n",
    "timings = []\n",
    "dialogs = []\n",
    "conversations = []\n",
    "speakers = []\n",
    "for i, corpus_multi_dict in enumerate(corporea_multi_dict):\n",
    "    begin = 0\n",
    "    end = 0\n",
    "    sentence = ''        \n",
    "    timing = []\n",
    "    dialog = []\n",
    "    conversation = []\n",
    "    speak = []\n",
    "    agent = agent_speaker[i]\n",
    "    client = client_speaker[i]\n",
    "    try:\n",
    "        speaker = corpus_multi_dict[0]['speaker']\n",
    "        for j, word in enumerate(corpus_multi_dict):\n",
    "            if word['speaker'] == speaker:\n",
    "                sentence += f\"{word['word']} \"\n",
    "            else:\n",
    "                end = corpus_multi_dict[j-1]['end']\n",
    "                timing.append([begin,end])\n",
    "                if speaker == agent: label = 'agent'\n",
    "                elif speaker == client: label = 'client'\n",
    "                else: label = 'none'\n",
    "                dialog.append({'file': i+1, 'pos':len(dialog)+1, 'speaker': speaker, 'label': label, 'sentence':sentence[:-1]})\n",
    "                conversation.append(sentence[:-1])\n",
    "                speak.append(speaker)\n",
    "                sentence = f\"{word['word']} \"\n",
    "                speaker = word['speaker']\n",
    "                begin = word['begin']\n",
    "        end = word['end']\n",
    "    except:\n",
    "        pass\n",
    "    timing.append([begin,end])\n",
    "    dialog.append({'file': i+1, 'pos':len(dialog)+1, 'speaker': speaker, 'label': label, 'sentence':sentence[:-1]})\n",
    "    conversation.append(sentence[:-1])\n",
    "    speak.append(speaker)\n",
    "    timings.append(timing)\n",
    "    dialogs.append(dialog)\n",
    "    conversations.append(conversation)\n",
    "    speakers.append(speak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dialogs_trans = {key:[] for key, value in dialogs[0][0].items()}\n",
    "dialogs_trans = {'file':[], 'pos':[], 'agent':[], 'sentence':[]}\n",
    "for dialog in dialogs:\n",
    "    for sentence in dialog:\n",
    "        for key, value in sentence.items():\n",
    "            if key == 'label':\n",
    "                if value == 'agent': dialogs_trans['agent'].append(1)\n",
    "                else: dialogs_trans['agent'].append(0)\n",
    "            elif key != 'speaker': dialogs_trans[key].append(value)\n",
    "\n",
    "dialogs_df = pd.DataFrame()\n",
    "for key, value in dialogs_trans.items():\n",
    "    dialogs_df[key] = value\n",
    "dialogs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for conversation in conversations:\n",
    "    document = \"\"\n",
    "    for sentence in conversation:\n",
    "        document = f\"{document}{sentence}. \"\n",
    "    document = document[:-1]\n",
    "    documents.append(document)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metrics data\n",
    "dialogs_df.to_csv(f\"{mypath}/transcripts/results/dialogs.csv\", index=False, encoding='utf8')\n",
    "tosave = {  'audio_metrics'         : audio_metrics,\n",
    "            'corporea'              : corporea,\n",
    "            'corporea_multi'        : corporea_multi,\n",
    "            'corporea_multi_dict'   : corporea_multi_dict,\n",
    "            'dialogs'               : dialogs,\n",
    "            'speakers'              : speakers}\n",
    "for key, data in tosave.items():\n",
    "    with open(f\"{mypath}/transcripts/results/{key}.json\", 'w', encoding='utf8') as json_file:\n",
    "        json.dump(data, json_file, ensure_ascii=False)\n",
    "        \n",
    "# save audio_metrics to excel file\n",
    "with open(f\"{mypath}/transcripts/results/audio_metrics.json\", 'r', encoding='utf8') as json_file:\n",
    "    data = json.loads(json_file.read())\n",
    "df_audio_metrics = pd.json_normalize(data)\n",
    "df_audio_metrics.to_excel(f\"{mypath}/transcripts/results/audio_metrics.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # individual save\n",
    "# onlysave = {'audio_metrics': audio_metrics,}\n",
    "# for key, data in onlysave.items():\n",
    "#     with open(f\"{mypath}/transcripts/results/{key}.json\", 'w', encoding='utf8') as json_file:\n",
    "#         json.dump(data, json_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "key = os.environ['AZURE_KEY']\n",
    "endpoint = os.environ['AZURE_ENDPOINT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SENTIMENT\n",
    "def sentiment_analysis(client, documents=[\"Tuve el mejor día de mi vida. Desearía que hubieras estado ahí.\"]):\n",
    "    sentiments = []\n",
    "    for document in documents:\n",
    "        response = client.analyze_sentiment([document])[0] #Llamada al servicio\n",
    "        sentiments.append(response)\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODIFICAR\n",
    "def sentiment_analysis_example(client, documents=[\"Tuve el mejor día de mi vida. Desearía que hubieras estado ahí.\"]):\n",
    "    response = client.analyze_sentiment(documents) #Llamada al servicio\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = sentiment_analysis(client, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for i in range(len(sentiments)):\n",
    "    numbers.append(len(sentiments[i].sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Datos Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traer_deuda(rut = rut[90],codemp = audio_cartera[90],pais = 152)\n",
    "# traer_deuda(rut = '003421657-6',codemp = 'CAT',pais = 152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "def traer_deuda(rut,codemp,pais):\n",
    "    URL = 'https://api-recsaone.recsa.cl/api/malena/cliente-acciones'\n",
    "    PARAMS = {'accion':'traer_deudas',\n",
    "                'rut':rut,\n",
    "                'cod_emp':codemp,\n",
    "                'usuario':'voicebot',\n",
    "                'cod_cli':'',\n",
    "                'pais':pais}\n",
    "    HEADERS = {'api-key':os.environ['API_RECSAONE'],\n",
    "                'Content-Type':'application/json',\n",
    "                'Accept':'application/json'}\n",
    "    r = requests.post(url=URL, params=PARAMS, headers=HEADERS)\n",
    "    data = r.json()\n",
    "    return data\n",
    "\n",
    "nombres = []\n",
    "for i,r in enumerate(rut):\n",
    "    data = traer_deuda(rut = r,codemp = audio_cartera[i],pais = 152)\n",
    "    if i==50: time.sleep(40)\n",
    "    try:\n",
    "        nombres.append(data['Nombre'])\n",
    "    except:\n",
    "        nombres.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "calidad = []\n",
    "for i,document in enumerate(documents):\n",
    "    if document == '.': calidad.append('Vacio')\n",
    "    elif isinstance(nombres[i],dict): calidad.append('Error API')\n",
    "    else:\n",
    "        mencionado = False\n",
    "        document_normalized = normalize('NFC', re.sub(r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", normalize( \"NFD\", document), 0, re.I))\n",
    "        for nombre in nombres[i].split():\n",
    "            if nombre.lower() in document_normalized: mencionado = True\n",
    "        if mencionado: calidad.append('Mencionado')\n",
    "        else: calidad.append('No Mencionado')\n",
    "len(calidad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NoMencionado_index = [i for i,cal in enumerate(calidad) if cal == 'No Mencionado']\n",
    "# Mencionado_index = [i for i,cal in enumerate(calidad) if cal == 'Mencionado']\n",
    "# print(NoMencionado_index)\n",
    "# print(Mencionado_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NoMencionado = [corporea[i] for i in NoMencionado_index]\n",
    "# Mencionado = [corporea[i] for i in Mencionado_index]\n",
    "# NoMencionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docx dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_LINE_SPACING\n",
    "from docx.shared import RGBColor\n",
    "\n",
    "indent = 1.5\n",
    "for n, conversation in enumerate(conversations):\n",
    "    timing = timings[n]\n",
    "    # sentences = sentiments[n].sentences\n",
    "    document = Document()\n",
    "    docx_name = audio_metrics[n]['file_name']\n",
    "    metric = []\n",
    "    metric.append(f\"rut: {audio_metrics[n]['rut']}\")\n",
    "    metric.append(f\"time_call: {audio_metrics[n]['time_call']:.2f} s\")\n",
    "    metric.append(f\"agent_name: {audio_metrics[n]['agent_name']}\")\n",
    "    metric.append(f\"cartera: {audio_metrics[n]['cartera']}\")\n",
    "    metric.append(f\"agent_dominance: {audio_metrics[n]['agent_dominance']*100:.0f}%\")\n",
    "    metric.append(f\"agent_words_per_second: {audio_metrics[n]['agent_words_per_second']:.2f} wps\")\n",
    "    metric.append(f\"client_words_per_second: {audio_metrics[n]['client_words_per_second']:.2f} wps\")\n",
    "    # metric.append(f\"conversation sentiment: {sentiments[n].sentiment}\")\n",
    "    # metric.append(f\"overall scores: positive={sentiments[n].confidence_scores.positive:.2f}; neutral={sentiments[n].confidence_scores.neutral:.2f}; negative={sentiments[n].confidence_scores.negative:.2f}\")\n",
    "\n",
    "    paragraph = document.add_heading(level=0)\n",
    "    paragraph_format = paragraph.paragraph_format\n",
    "    paragraph_format.space_after = Pt(3)\n",
    "    run = paragraph.add_run(f'{docx_name}')\n",
    "    run.font.size = Pt(16)\n",
    "\n",
    "    for m in metric:\n",
    "        paragraph = document.add_paragraph()\n",
    "        paragraph_format = paragraph.paragraph_format\n",
    "        paragraph.add_run(str(m)).font.size = Pt(9)\n",
    "        paragraph_format.space_after = Pt(0)\n",
    "    paragraph_format.space_after = Pt(9)\n",
    "\n",
    "    begin = 0\n",
    "    left = True\n",
    "    for s in speakers[n]:\n",
    "        if s == agent_speaker[n] or s == client_speaker[n]:\n",
    "            if s == agent_speaker[n]:\n",
    "                left = False\n",
    "            break\n",
    "    for i, sentence in enumerate(conversation):\n",
    "        if speakers[n][i] == agent_speaker[n] or speakers[n][i] == client_speaker[n]:\n",
    "            paragraph = document.add_paragraph()\n",
    "            # timestamp = f\"{sentences[i].sentiment} | pos:{sentences[i].confidence_scores.positive:.2f} | neu:{sentences[i].confidence_scores.neutral:.2f} | neg:{sentences[i].confidence_scores.negative:.2f} | [{timing[i][0]:.1f}, {timing[i][1]:.1f}]s\"\n",
    "            timestamp = f\"[{timing[i][0]:.1f}, {timing[i][1]:.1f}]s\"\n",
    "            if left:\n",
    "                paragraph.add_run(f'{sentence}').font.color.rgb = RGBColor(0,176,80)\n",
    "                paragraph.paragraph_format.right_indent = Inches(indent)\n",
    "                paragraph.paragraph_format.space_after = Pt(0)\n",
    "                paragraph = document.add_paragraph()\n",
    "                paragraph.add_run(f'{i+1}. {timestamp}').font.size = Pt(7)\n",
    "                paragraph.paragraph_format.right_indent = Inches(indent)\n",
    "            else:\n",
    "                paragraph.add_run(f'{sentence}').font.color.rgb = RGBColor(0,112,192)\n",
    "                paragraph.paragraph_format.left_indent = Inches(indent)\n",
    "                paragraph.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "                paragraph.paragraph_format.space_after = Pt(0)\n",
    "                paragraph = document.add_paragraph()\n",
    "                paragraph.add_run(f'{i+1}. {timestamp}').font.size = Pt(7)\n",
    "                paragraph.paragraph_format.left_indent = Inches(indent)\n",
    "                paragraph.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.RIGHT\n",
    "            paragraph.paragraph_format.space_after = Pt(6)\n",
    "            left = not left\n",
    "    document.add_page_break()\n",
    "    document.save(f\"{mypath}/transcripts/docx/{docx_name}.docx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
